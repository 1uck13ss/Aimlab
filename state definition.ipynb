{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846294d4-eab5-45f0-9b28-72f1f9184eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video processing\n",
    "!pip install opencv-python\n",
    "#training model\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install yolov5/requirements.txt\n",
    "#label images\n",
    "!pip install labelImg\n",
    "!pip install setuptools\n",
    "#getting screenshots\n",
    "!pip install mss\n",
    "#allows cpu to make movement \n",
    "!pip install pyautogui\n",
    "!pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279bb01-1909-40f2-a8cc-6698302875d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import os\n",
    "from mss import mss\n",
    "import torch\n",
    "import pytesseract\n",
    "from interception import beziercurve\n",
    "import interception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cca5b-e47c-41a7-b54e-c7d458ecb0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 videos to process.\n",
      "\n",
      "Processing: vid1.mp4...\n",
      "Extracted 130 frames.\n",
      "Splitting into 104 training and 26 test frames.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "video_path = r\".\\Video\"\n",
    "temp_dir = r\".\\temp_frames\"\n",
    "train_dir = r\".\\dataset\\images\\train\"\n",
    "test_dir = r\".\\dataset\\images\\test\"\n",
    "test_split = 0.2  \n",
    "\n",
    "for directory in [temp_dir, train_dir, test_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "#extracting frames from video and splitting them into training and validation sets\n",
    "def process_video_directory(input_dir):\n",
    "    video_extensions = ('.mp4') \n",
    "    video_files = [\n",
    "        os.path.join(input_dir, f)\n",
    "        for f in os.listdir(input_dir)\n",
    "        if f.lower().endswith(video_extensions)\n",
    "    ]\n",
    "\n",
    "    if not video_files:\n",
    "        print(f\"No video files found in directory: {input_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(video_files)} videos to process.\")\n",
    "    extracted_frames = []\n",
    "\n",
    "    for idx, video_path in enumerate(video_files):\n",
    "        video_name = os.path.basename(video_path)\n",
    "        print(f\"\\nProcessing: {video_name}...\")\n",
    "        count = extract_frames_from_video(video_path, video_name, extracted_frames)\n",
    "        print(f\"Extracted {count} frames.\")\n",
    "\n",
    "    random.shuffle(extracted_frames)\n",
    "    split_idx = int(len(extracted_frames) * (1 - test_split))\n",
    "    train_frames = extracted_frames[:split_idx]\n",
    "    test_frames = extracted_frames[split_idx:]\n",
    "\n",
    "    print(f\"Splitting into {len(train_frames)} training and {len(test_frames)} test frames.\")\n",
    "\n",
    "    for frame in train_frames:\n",
    "        shutil.move(os.path.join(temp_dir, frame), os.path.join(train_dir, frame))\n",
    "\n",
    "    for frame in test_frames:\n",
    "        shutil.move(os.path.join(temp_dir, frame), os.path.join(test_dir, frame))\n",
    "\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(\"Done.\")\n",
    "\n",
    "def extract_frames_from_video(video_path, video_name, frames):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_name}\")\n",
    "        return 0\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % int(fps) == 0:\n",
    "            frame_filename = f\"{os.path.splitext(video_name)[0]}_frame{frame_count}.jpg\"\n",
    "            frame_path = os.path.join(temp_dir, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frames.append(frame_filename)\n",
    "            saved_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return saved_count\n",
    "\n",
    "process_video_directory(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3610e-4c4f-4602-b821-9b45db28b495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\limju\\AppData\\Local\\Temp\\ipykernel_27788\\3313658992.py:20: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  clean_label_filenames(\"dataset\\labels\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done renaming\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#cleaning up the labels\n",
    "def clean_label_filenames(root_folder):\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".txt\") and \"-\" in filename:\n",
    "                new_name = filename.split(\"-\", 1)[1]\n",
    "                src_path = os.path.join(dirpath, filename)\n",
    "                dst_path = os.path.join(dirpath, new_name)\n",
    "\n",
    "                # Rename only if new name is different\n",
    "                if src_path != dst_path:\n",
    "                    os.rename(src_path, dst_path)\n",
    "                else:\n",
    "                    print(filename)\n",
    "    print(\"done renaming\")\n",
    "\n",
    "clean_label_filenames(\"dataset\\labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c08a0-5b2d-4a87-9327-27f74c75ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training yolo model\n",
    "!python yolov5/train.py --img 640 --batch 16 --epochs 50 --data dataset.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d978efd-51cd-4f27-8ff4-073485082383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base for detection\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"custom\", path=\"yolov5/runs/train/exp/weights/best.pt\")\n",
    "\n",
    "monitor = {\"top\": 0, \"left\": 0, \"width\": 1920, \"height\": 1080}\n",
    "\n",
    "frame_count = 0\n",
    "inference_interval = 5  \n",
    "\n",
    "with mss() as sct:\n",
    "    while True:\n",
    "        frame = np.array(sct.grab(monitor))\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        # debugging (ensure that the bots are properly lablaed)\n",
    "        if frame_count % inference_interval == 0:\n",
    "            results = model(frame)\n",
    "            detections = results.xyxy[0].cpu().numpy()  \n",
    "        \n",
    "            \n",
    "            for detection in detections:\n",
    "                x_min, y_min, x_max, y_max, confidence, class_id = detection\n",
    "                label = f\"Bot {confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Bot Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64e53d-fc92-4739-bd01-6eb656cd90a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0\n",
      "Accuracy: 29%\n"
     ]
    }
   ],
   "source": [
    "# detect the scores using OCR\n",
    "image = cv2.imread(\"dataset/images/train/vid1_frame1080.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "x1_rel, y1_rel = 0.31, 0.055\n",
    "x2_rel, y2_rel = 0.425, 0.1\n",
    "\n",
    "x1 = int(x1_rel * width)\n",
    "y1 = int(y1_rel * height)\n",
    "x2 = int(x2_rel * width)\n",
    "y2 = int(y2_rel * height)\n",
    "\n",
    "score_roi = gray[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "x1_rel, y1_rel = 0.56, 0.055\n",
    "x2_rel, y2_rel = 0.6, 0.1\n",
    "\n",
    "x1 = int(x1_rel * width)\n",
    "y1 = int(y1_rel * height)\n",
    "x2 = int(x2_rel * width)\n",
    "y2 = int(y2_rel * height)\n",
    "\n",
    "accuracy_roi = gray[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "score_roi = cv2.threshold(score_roi, 127, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "accuracy_roi = cv2.threshold(accuracy_roi, 127, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "score_text = pytesseract.image_to_string(score_roi, config='--psm 7')\n",
    "accuracy_text = pytesseract.image_to_string(accuracy_roi, config='--psm 7')\n",
    "\n",
    "print(\"Score:\", score_text.strip())\n",
    "print(\"Accuracy:\", accuracy_text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70915724-1825-452a-91fb-0f0a4f2245ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# able to simualte accurate hand movement\n",
    "# unable to use relative mouse movement\n",
    "params = beziercurve.BezierCurveParams()\n",
    "params.duration = 1.5        \n",
    "params.smoothness = 0.005   \n",
    "\n",
    "interception.move_relative(0, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitest",
   "language": "python",
   "name": "aitest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
